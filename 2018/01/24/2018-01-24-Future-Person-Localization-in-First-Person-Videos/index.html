<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="keywords" content="卡丘, 卡丘"><meta name="description" content="Let's try!"><title>《Future Person Localization in First-Person Videos》笔记 | 卡丘</title><link rel="icon" href="/assets/favicon-16x16.png?v=1.5.4" type="image/png" sizes="16x16"><link rel="icon" href="/assets/favicon-32x32.png?v=1.5.4" type="image/png" sizes="32x32"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=1.5.4"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontawesome: {"prefix":"fa"},
  sidebar: {"offsetTop":"30px","renderTocDepth":4},
  header: {"scrollDownIcon":false},
  back2top: {"enable":true},
  reward: false,
  fancybox: false,
  zoom_image: {"enable":true,"mask_color":"rgba(0,0,0,0.6)"},
  gallery_waterfall: undefined,
  lazyload: undefined,
  pjax: undefined,
  external_link: {"icon":{"enable":true,"name":"external-link"}},
  shortcuts: {"switch_post":false},
  prompt: {"copy_success":"复制成功","copy_error":"复制失败","creative_commons":"知识共享","copy_button":"点击复制"}
};

window.CONFIG = CONFIG;</script></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav"><div class="header-nav-inner"><div class="header-nav-btn fa fa-bars"></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/"><i class="fa fa-home"></i>首页</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/archives/"><i class="fa fa-folder-open"></i>归档</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/categories/"><i class="fa fa-th"></i>分类</a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__a" href="/tags/"><i class="fa fa-tags"></i>标签</a></div></div></div></nav><div class="header-info"><div class="header-info-inner"><div class="header-info-title">卡丘</div><div class="header-info-subtitle">PICulture</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content"><div class="post"><header class="post-header"><h1 class="post-header-title">《Future Person Localization in First-Person Videos》笔记</h1><div class="post-header-meta"><span class="post-header-meta-create"><i class="fa fa-calendar-o"></i><span>发表于 </span><span>2018-01-24</span></span><span class="post-header-meta-update"><i class="fa fa-calendar-check-o"></i><span>更新于 </span><span>2018-01-24</span></span></div></header><div class="post-body"><p>在知乎上看到的一篇文章——论文笔记：<span class="external-link"><a href="https://zhuanlan.zhihu.com/p/31777423" target="_blank" rel="noopener">第一人称视角视频中的行人轨迹预测</a><i class="fa fa-external-link"></i></span>，论文的题目是<span class="external-link"><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1711.11217" target="_blank" rel="noopener">Future Person Localization in First-Person Videos</a><i class="fa fa-external-link"></i></span>，结合行人目标跟踪内容，简单做一下梳理。</p>
<p><img src="http://p31vl29qj.bkt.clouddn.com/201801241552_572.png" alt></p>
<h4 id="研究内容"><span class="heading-link">研究内容</span></h4><p>文章的研究内容是，在可穿戴相机（wearable cameras）拍摄的第一人称视频（First-person videos）的基础上，已知t时刻及之前几帧图像中行人的相关信息，要求算法预测未来几帧中该行人会出现在图像中的什么位置。这点与目标跟踪的区别是：目标跟踪中大多是将视频每一帧的特征信息以一定的权重融合在一起，预测时仅预测后一帧的具体位置。</p>
<h4 id="特征提取"><span class="heading-link">特征提取</span></h4><p>文章提取了四种特征序列：</p>
<ol>
<li>行人检测框的位置序列（Location）；</li>
<li>行人检测框的大小序列（Scale），在第一人称视角中，行人框的大小实际上隐含了透视投影的关系，即“近大远小”；</li>
<li>行人的骨架序列（Pose），骨架信息主要隐含了行人的动作，姿态，朝向等信息；</li>
<li>摄像机本身的运动信息（Ego-motion），由于第一人称视角中相机本身也是在不断运动的，所以相机本身的运动也不得不考虑进算法当中，具体而言，就是相机在每两帧之间的平移和旋转信息。</li>
</ol>
<p>后面比较和目标跟踪的区别：</p>
<ol>
<li>在跟踪中，主要利用的是前一帧目标的位置，以此划定一个区域作为下一帧目标位置估计的搜索范围。由于目标的运动状态不定，根据前数帧目标运动轨迹信息对后续预测的结果不确定。（马路上的行人大多数方向是确定的，一般不会突然掉头吧）。</li>
<li>跟踪中对待尺度的方法有多种，比较流行的是将目标乘以不同的尺度系数， resize 为原来的大小，通过检测器检测出分值最高的那一种尺度。</li>
<li>跟踪中的特征主要为 HOG + 深度特征。</li>
<li>对于目标的快速运动或者是相机的快速运动，跟踪效果不好。</li>
</ol>
<p>具体的采取特征的方法：</p>
<ol>
<li>骨架信息：CMU 开源的 <span class="external-link"><a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" target="_blank" rel="noopener">OpenPose</a><i class="fa fa-external-link"></i></span></li>
<li>相机自身的运动信息：本文则采用了<span class="external-link"><a href="https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/cvpr17_sfm_final.pdf" target="_blank" rel="noopener">这篇论文</a><i class="fa fa-external-link"></i></span>中的算法来进行进行估计</li>
</ol>
<h4 id="实施方法"><span class="heading-link">实施方法</span></h4><p>研究的问题表示为：已知 $t$ 时刻及前 $T_{prev}$  帧的四种 feature序列，要求预测后 $T_{future}$ 帧的行人检测框位置序列。本文提出了一个很简单的基于 1 维卷积的网络，如下图所示：</p>
<p><img src="http://p31vl29qj.bkt.clouddn.com/201801241629_966.png" alt="提出的网络结构"></p>
<p>具体的配置为：</p>
<p><img src="http://p31vl29qj.bkt.clouddn.com/201801241631_183.png" alt="网络结构"></p>
<h4 id="实验分析"><span class="heading-link">实验分析</span></h4><p>本文与几种行人轨迹预测的 baseline 进行了比较，还对输入的几种特征进行了 ablation<br>study ，表明综合多种信息对于轨迹的预测效果有着显著的提高效果。</p>
<h4 id="小结"><span class="heading-link">小结</span></h4><p>这篇论文的想法可以融合到目标跟踪的算法之中，可以尝试构建复杂的特征融合算法放到相关滤波的框架试一试效果怎么样。</p>
</div><footer class="post-footer"><div class="post-end"><span>------ </span><span>本文结束，感谢您的阅读</span><span> ------</span></div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-author-name">本文作者: </span><span class="post-copyright-author-value"><a href="https://piculture.github.io">卡丘</a></span></div><div class="post-copyright-link"><span class="post-copyright-link-name">本文链接: </span><span class="post-copyright-link-value"><a href="https://piculture.github.io/2018/01/24/2018-01-24-Future-Person-Localization-in-First-Person-Videos/">https://piculture.github.io/2018/01/24/2018-01-24-Future-Person-Localization-in-First-Person-Videos/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-notice-name">版权声明: </span><span class="post-copyright-notice-value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><i class="post-tags-item__i fa fa-tags"></i><a class="post-tags-item__a" href="https://piculture.github.io/tags/%E8%AE%BA%E6%96%87/">论文</a></span><span class="post-tags-item"><i class="post-tags-item__i fa fa-tags"></i><a class="post-tags-item__a" href="https://piculture.github.io/tags/%E8%A1%8C%E4%BA%BA/">行人</a></span><span class="post-tags-item"><i class="post-tags-item__i fa fa-tags"></i><a class="post-tags-item__a" href="https://piculture.github.io/tags/%E8%BD%A8%E8%BF%B9%E9%A2%84%E6%B5%8B/">轨迹预测</a></span></div><nav class="paginator"><div class="paginator-post"><div class="paginator-post-prev"><a class="paginator-post-prev__a" href="/2018/02/09/2018-02-09-nova-launcher/"><i class="fa fa-chevron-left"></i><span>nova launcher 相关使用说明</span></a></div><div class="paginator-post-next"><a class="paginator-post-next__a" href="/2018/01/23/2018-01-23-hexo-github-pages-blog/"><span>Hexo+Github博客搭建和优化</span><i class="fa fa-chevron-right"></i></a></div></div></nav></footer></div></div></div><aside class="sidebar" id="sidebar"><div class="sidebar-inner"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#研究内容"><span class="toc-number">1.</span> <span class="toc-text">研究内容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#特征提取"><span class="toc-number">2.</span> <span class="toc-text">特征提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实施方法"><span class="toc-number">3.</span> <span class="toc-text">实施方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实验分析"><span class="toc-number">4.</span> <span class="toc-text">实验分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#小结"><span class="toc-number">5.</span> <span class="toc-text">小结</span></a></li></ol></div></section><!-- ov = overview --><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/favicon.png" alt="avatar"></div><p class="sidebar-ov-author__p">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state__a posts" href="/archives/"><div class="sidebar-ov-state__a--count">20</div><div class="sidebar-ov-state__a--name">归档</div></a><a class="sidebar-ov-state__a categories" href="/categories/"><div class="sidebar-ov-state__a--count">19</div><div class="sidebar-ov-state__a--name">分类</div></a><a class="sidebar-ov-state__a tags" href="/tags/"><div class="sidebar-ov-state__a--count">21</div><div class="sidebar-ov-state__a--name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg" alt="知识共享"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span>你已阅读了 </span><span class="sidebar-reading-info-num">0</span></div><div class="sidebar-reading-line"></div></div></div></aside><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>&copy; 2019</span><span class="fa fa-heart footer-icon"></span><span>卡丘.</span></div><div><span>由 <a href="http://hexo.io/" title="hexo" target="_blank" rel="noopener">hexo</a> 强力驱动</span><span> v4.0.0.</span><span class="separator">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="stun" target="_blank" rel="noopener">stun</a></span><span> v1.5.4.</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="progress"></div></div><div class="back2top" id="back2top"><i class="back2top-icon fa fa-rocket"></i></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=1.5.4"></script><script src="/js/stun-boot.js?v=1.5.4"></script><script src="/js/scroll.js?v=1.5.4"></script><script src="/js/header.js?v=1.5.4"></script><script src="/js/sidebar.js?v=1.5.4"></script></body></html>